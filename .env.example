# Azure OpenAI API Key 配置
DOCUFLOW_AZURE_OPENAI_API_KEY=
DOCUFLOW_MODEL_NAME=deepseek-v3.2
# Azure OpenAI 端点和部署配置
# GPT5.2 部署
GPT5.2_AZURE_OPENAI_ENDPOINT=https://openapi-dev-intern.cognitiveservices.azure.com
GPT5.2_AZURE_OPENAI_DEPLOYMENT=gpt-5.2
GPT5.2_AZURE_OPENAI_API_VERSION=2025-04-01-preview

#GPT5.1code
GPT5.1_AZURE_OPENAI_ENDPOINT=https://openapi-dev-intern.cognitiveservices.azure.com
GPT5.1_AZURE_OPENAI_DEPLOYMENT=gpt-5.1-codex-max
GPT5.1_AZURE_OPENAI_API_VERSION=2025-04-01-preview

# deepseek-v3.2 部署
DeepSeek-V3.2_AZURE_OPENAI_ENDPOINT=https://openapi-dev-intern.services.ai.azure.com
DeepSeek-V3.2_AZURE_OPENAI_DEPLOYMENT=DeepSeek-V3.2
DeepSeek-V3.2_AZURE_OPENAI_API_VERSION=2024-05-01-preview

# 批判模型设计
DOCUFLOW_CRITIQUE_ENABLED=true       # 默认启用
DOCUFLOW_CRITIQUE_THRESHOLD=0.7      # 通过阈值
DOCUFLOW_CRITIQUE_MAX_ITERATIONS=2   # 最大迭代次数
DOCUFLOW_CRITIQUE_MODEL=             # 批判使用的模型（可选，留空则使用主模型）
                                     # 可选值: gpt-5.2, gpt-5.1, deepseek-v3.2

# LLM 并发和速率限制配置
# 注意：这些参数需要根据 Azure OpenAI 配额调整
# 查看配额: Azure Portal -> Azure OpenAI -> Quotas (RPM = Requests Per Minute)
# 
# 推荐配置（60 RPM 配额）:
#   - LLM_TIMEOUT: 180
#   - LLM_MAX_CONCURRENT: 5
#   - RATE_LIMIT_REQUESTS_PER_SECOND: 0.9 (54 req/min，留10%余量)
#   - MAX_BUCKET_SIZE: 10
#
# 详细说明请参考: CONCURRENCY_TUNING.md

DOCUFLOW_LLM_TIMEOUT=180             # LLM请求超时秒数（建议 180-300）
DOCUFLOW_LLM_MAX_CONCURRENT=5        # 最大并发请求数（建议 5-10，根据配额调整）
DOCUFLOW_LLM_MAX_RETRIES_SDK=3       # SDK 内部重试次数（处理瞬态错误）

DOCUFLOW_LLM_RATE_LIMIT_ENABLED=true # 是否启用速率限制（强烈建议启用）
DOCUFLOW_LLM_RATE_LIMIT_REQUESTS_PER_SECOND=0.9  # 每秒请求数（根据 Azure RPM 配额设置）
DOCUFLOW_LLM_RATE_LIMIT_CHECK_EVERY_N_SECONDS=0.1  # 速率检查间隔
DOCUFLOW_LLM_RATE_LIMIT_MAX_BUCKET_SIZE=10  # 最大突发请求数（令牌桶大小）

# API 服务配置
DOCUFLOW_API_MAX_WORKERS=4           # API 线程池大小（同时处理的项目数）